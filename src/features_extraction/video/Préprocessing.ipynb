{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Préprocessing.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"ZsL0jgSmgLhT","colab_type":"text"},"cell_type":"markdown","source":["####Imports"]},{"metadata":{"id":"oY7GLfivQyjw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"71d25d2c-e148-42c0-c7e7-e1c7e310f107","executionInfo":{"status":"ok","timestamp":1541767952833,"user_tz":-60,"elapsed":1771,"user":{"displayName":"alex dudu","photoUrl":"","userId":"10827822465940504674"}}},"cell_type":"code","source":["%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from matplotlib.image import imread, imsave\n","import cv2\n","from tqdm import tqdm\n","import os\n","import glob\n","import shutil\n","from sklearn import svm, grid_search, datasets\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from random import shuffle"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n","  \"This module will be removed in 0.20.\", DeprecationWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n","  DeprecationWarning)\n"],"name":"stderr"}]},{"metadata":{"id":"z-_Vj-yTmMI7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":275},"outputId":"2621f72f-9d65-4734-fd60-daecf4890929","executionInfo":{"status":"ok","timestamp":1541768008405,"user_tz":-60,"elapsed":7096,"user":{"displayName":"alex dudu","photoUrl":"","userId":"10827822465940504674"}}},"cell_type":"code","source":["! pip install imageio\n","! pip install opencv-python"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting imageio\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b4/cbb592964dfd71a9de6a5b08f882fd334fb99ae09ddc82081dbb2f718c81/imageio-2.4.1.tar.gz (3.3MB)\n","\u001b[K    100% |████████████████████████████████| 3.3MB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.14.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (4.0.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio) (0.46)\n","Building wheels for collected packages: imageio\n","  Running setup.py bdist_wheel for imageio ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e0/43/31/605de9372ceaf657f152d3d5e82f42cf265d81db8bbe63cde1\n","Successfully built imageio\n","Installing collected packages: imageio\n","Successfully installed imageio-2.4.1\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.3.18)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n"],"name":"stdout"}]},{"metadata":{"id":"qcWL4S-2eWBp","colab_type":"text"},"cell_type":"markdown","source":["    data  \n","        text  \n","        audio  \n","        video  \n"]},{"metadata":{"id":"2Wtbq2zsioVz","colab_type":"text"},"cell_type":"markdown","source":["##Préprocessing\n","\n","- fonctions propres et commentées :\n","    - video_to_frames_onepersec : extraction des frames d'une vidéo (une par seconde)\n","    - video_to_frames_onepercut : extraction des frames d'une vidéo (une par plan)\n","    \n","    \n","###Calcul Descripteurs\n","\n","- formattage en vecteur pour préparer la classification\n","\n","- couleur : ...\n","- contour : ...\n","\n","\n","- librairie YOLO ?\n","- etc\n","\n","### Mémo\n","\n","- `cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)` : convertire image en niveaux de gris\n","- `imread` pour lire une image avec `matplotlib`\n","- https://bcastell.com/posts/scene-detection-tutorial-part-1/"]},{"metadata":{"id":"or26Z6qxQB1Q","colab_type":"code","outputId":"93b3b6fb-e8a2-440b-b4dc-6721aae3f977","executionInfo":{"status":"ok","timestamp":1540889470780,"user_tz":-60,"elapsed":27051,"user":{"displayName":"Pierrick Herve","photoUrl":"https://lh3.googleusercontent.com/-k_fs7F7thlQ/AAAAAAAAAAI/AAAAAAAAAdA/hM4l3zul944/s64/photo.jpg","userId":"05416953357448572451"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"cell_type":"code","source":["from google.colab import files, drive, auth\n","import os\n","\n","drive.mount(\"/content/gdrive\", force_remount=False)\n","\n","PATH = \"/content/gdrive/My Drive/AED/\"\n","\n","if os.path.isfile(f\"{PATH}data.zip\"): #and not os.path.isdir(\"data/\"):\n","    print(\"\\nUnziping the data...\")\n","    !unzip -q gdrive/My\\ Drive/AED/data.zip\n","    print(\"Done.\")\n","else:\n","    print(\"\\nData directory already ready.\")\n","\n","\n","PATH = \"/content/gdrive/My Drive/AED/\"\n","if os.path.isfile(f\"{PATH}image_3.zip\") and not os.path.isdir(\"data/image_3\"):\n","    print(\"\\nUnziping the data...\")\n","    !mkdir -p data/image_3/\n","    !unzip -q gdrive/My\\ Drive/AED/image_3 -d data/image_3/\n","    print(\"Done.\")\n","else:\n","    print(\"\\nData directory already ready.\")\n","    \n","if os.path.isfile(f\"{PATH}image_sec.zip\") and not os.path.isdir(\"data/image_sec\"):\n","    print(\"\\nUnziping the data...\")\n","    !mkdir -p data/image_sec/\n","    !unzip -q gdrive/My\\ Drive/AED/image_sec -d data/image_sec/\n","    print(\"Done.\")\n","else:\n","    print(\"\\nData directory already ready.\")\n","    \n","if os.path.isfile(f\"{PATH}image_200.zip\"): #and not os.path.isdir(\"data/image_sec\"):\n","    print(\"\\nUnziping the data...\")\n","    !mkdir -p data/image_sec/\n","    !unzip -q gdrive/My\\ Drive/AED/image_200 -d data/image_sec/\n","    print(\"Done.\")\n","else:\n","    print(\"\\nData directory already ready.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","\n","Unziping the data...\n"],"name":"stdout"}]},{"metadata":{"id":"4ZtXDwHChK5Y","colab_type":"text"},"cell_type":"markdown","source":["###Plot images"]},{"metadata":{"id":"M2kwxo0IfjNQ","colab_type":"code","colab":{}},"cell_type":"code","source":["def show_images(*args, col=3):\n","    \"\"\"\n","        Plot image(s)\n","        \n","        Take as param: list, str (for a folder's path) or np.ndarray.\n","    \"\"\"\n","    for arg in args:\n","        if isinstance(arg, list):\n","            images = arg\n","            rows = len(images) // col + 1\n","            fig = plt.figure(figsize=(col*8, rows*6))\n","            for i, image in enumerate(images):\n","                try:\n","                    fig.add_subplot(rows, col, i+1)\n","                    plt.imshow(image)\n","                    plt.grid(False)\n","                    plt.axis('off')\n","                    plt.title(i)\n","                except:\n","                    pass\n","        elif isinstance(arg, str):\n","            folder = arg\n","            paths = sorted(glob.glob(f\"{folder}/*.jpg\"))\n","            if not paths:\n","                print(f\"The folder '{folder}' does not contain any JPG image.\")\n","            else:\n","                rows = len(paths) // col + 1\n","                fig = plt.figure(figsize=(col*8, rows*6))\n","                for i, path in enumerate(paths):\n","                    try:\n","                        fig.add_subplot(rows, col, i+1)\n","                        plt.imshow(imread(path))\n","                        plt.grid(False)\n","                        plt.axis('off')\n","                        plt.title(i)\n","                    except:\n","                        pass\n","        elif isinstance(arg, np.ndarray):\n","            image = arg\n","            plt.figure(figsize=(8, 6))\n","            plt.imshow(image)\n","            plt.grid(False)\n","            plt.axis('off')\n","        else:\n","            print(\"Invalid type of argument (must be 'list', 'str' or 'np.ndarray')\")\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HrLnioDnPRfK","colab_type":"text"},"cell_type":"markdown","source":["###Transform a video into frames (one per second,  one per cut)"]},{"metadata":{"id":"JeRwf4fiX-iQ","colab_type":"code","colab":{}},"cell_type":"code","source":["def video_to_frames(videopath):\n","    frames = []\n","    vidcap = cv2.VideoCapture(videopath)\n","    framerate = int(vidcap.get(5))\n","    name = os.path.splitext(os.path.basename(videopath))[0]\n","    success, frame = vidcap.read()\n","    frame_number = 0\n","    while success:\n","        if frame_number % framerate == 0:\n","            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # convertion to RGB\n","            frames.append(frame)\n","        success, frame = vidcap.read() \n","        frame_number += 1\n","    return frames, framerate, name\n","\n","\n","def seq_to_3_frames(images):\n","    duration = len(images)\n","    tiers_values = [duration//4, duration//2, 3*duration//4]\n","    frames = [images[tiers] for tiers in tiers_values]\n","    return frames, duration\n","\n","\n","# f, framerate, n = video_to_frames(\"data/video/SEQ_003_VIDEO.mp4\")\n","# f, d = seq_to_3_frames(f)\n","\n","# show_images(f, col=3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uigtHpcfPh6b","colab_type":"text"},"cell_type":"markdown","source":["###Parse all videos to extract frames\n"]},{"metadata":{"id":"yyWWrmXzgSIQ","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","def build_image_folder(start=None, end=None):\n","    for videopath in ProgressBar((sorted(glob.glob(\"data/video/*.mp4\")))[start:end]):\n","        frames_per_sec, framerate, name = video_to_frames(videopath)\n","        folder = f\"data/image_sec/{name}\"\n","        os.makedirs(folder, exist_ok=True)\n","        for i, frame in enumerate(frames_per_sec):\n","            imsave(f\"{folder}/frame_{i:03}.jpg\", frame)\n","            \n","        frames_3, duration = seq_to_3_frames(frames_per_sec)\n","        folder = f\"data/image_3/{name}\"\n","        os.makedirs(folder, exist_ok=True)\n","        for i, frame in enumerate(frames_3):\n","            imsave(f\"{folder}/frame_{i}.jpg\", frame)\n","\n","    shutil.make_archive(\"image_3\", 'zip', \"data/image_3\")\n","    shutil.make_archive(\"image_sec\", 'zip', \"data/image_sec\")\n","    ! mv image_sec.zip \"/content/gdrive/My Drive/AED/\"\n","    ! mv image_3.zip \"/content/gdrive/My Drive/AED/\"\n","    \n","# build_image_folder()\n","# !ls /content/gdrive/My Drive/AED/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JaSlw56AjP-F","colab_type":"code","colab":{}},"cell_type":"code","source":["def folder_to_list(folder):\n","    paths = sorted(glob.glob(f\"{folder}/*.jpg\"))\n","    if paths:\n","        frames = []\n","        for path in paths:\n","            frames.append(imread(path))        \n","    else:\n","        print(f\"The folder '{folder}' does not contain any JPG image.\")\n","    return frames\n","\n","def folder_to_list_grey(folder):\n","    paths = sorted(glob.glob(f\"{folder}/*.jpg\"))\n","    if paths:\n","        frames = []\n","        for path in paths:\n","            frames.append(imread(path, 0))     \n","    else:\n","        print(f\"The folder '{folder}' does not contain any JPG image.\")\n","    return frames"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_DqlR8w7ndtH","colab_type":"text"},"cell_type":"markdown","source":["##Calcul descripteurs"]},{"metadata":{"id":"1Q3VY8qkc8Lz","colab_type":"text"},"cell_type":"markdown","source":["###Transform Images to Colours histograms"]},{"metadata":{"id":"0JsAZ6PbLDMU","colab_type":"code","colab":{}},"cell_type":"code","source":["# # def quantification(img, nbits = 2):\n","# #     num = 0\n","# #     for i in range(nbits):\n","# #         num += 128 / (2**i)  # on determine la valeur correspondant à la quantification\n","# #     Rouge = np.bitwise_and(img[:,:,0], int(num))  # en fonction du nombre de bits choisits\n","# #     Vert = np.bitwise_and(img[:,:,1], int(num))\n","# #     Bleu = np.bitwise_and(img[:,:,2], int(num))\n","# #     Rouge = np.floor(Rouge / (2**(8-3*nbits)))\n","# #     Vert = np.floor(Vert / (2**(8-2*nbits)))\n","# #     Bleu = np.floor(Bleu / (2**(8-nbits)))\n","# #     return Rouge + Vert + Bleu\n","\n","# def histogramme(img):\n","#     M = img.shape[0]\n","#     N = img.shape[1]\n","#     list_histo = []\n","#     val =1/(M*N)\n","#     for color in range(3):\n","#         histo = np.zeros(256)    \n","#         for i in range(M):\n","#             for j in range(N):\n","#                 histo[int(img[i,j, color])] += val\n","#         list_histo.append(histo)\n","#     return list_histo\n","        \n","# def dist_Manhattan(hist1, hist2):\n","#     return sum(np.abs(np.array(hist1) - np.array(hist2)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UtnRdnTbpIUz","colab_type":"text"},"cell_type":"markdown","source":["### Récupérer 200 images par séquence"]},{"metadata":{"id":"dFJKi6-1lwCK","colab_type":"code","colab":{}},"cell_type":"code","source":["def seq_to_200_frames(images):\n","    duration = len(images)\n","    tiers_values = []\n","    for i in range(1,201):\n","        tiers_values.append(i*duration//201)\n","#         tiers_values = [duration//201, 2*duration//11, 3*duration//11, 4*duration//11, 5*duration//11, 6*duration//11,\n","#                     7*duration//11, 8*duration//11, 9*duration//11, 10*duration//11]\n","    frames = [images[tiers] for tiers in tiers_values]\n","    return frames, duration"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6DRPxLenpI-S","colab_type":"code","colab":{}},"cell_type":"code","source":["def build_image_folder_200(start=None, end=None):\n","    for videopath in tqdm((sorted(glob.glob(\"data/video/*.mp4\")))[start:end]):\n","        frames_per_sec, framerate, name = video_to_frames(videopath)\n","        #folder = f\"data/image_sec/{name}\"\n","        #os.makedirs(folder, exist_ok=True)\n","        #for i, frame in enumerate(frames_per_sec):\n","        #    imsave(f\"{folder}/frame_{i:03}.jpg\", frame)\n","            \n","        frames_200, duration = seq_to_200_frames(frames_per_sec)\n","        folder = f\"data/image_200/{name}\"\n","        os.makedirs(folder, exist_ok=True)\n","        for i, frame in enumerate(frames_200):\n","            imageio.imwrite(f\"{folder}/frame_{i:03}.jpg\", frame)\n","\n","    shutil.make_archive(\"image_200\", 'zip', \"data/image_200\")\n","    ! mv image_200.zip \"/content/gdrive/My Drive/AED/\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"dNANmy0CdkUH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":429},"outputId":"ba86f984-5f72-4e5c-f9ad-228079e25c1c","executionInfo":{"status":"error","timestamp":1541767181745,"user_tz":-60,"elapsed":501,"user":{"displayName":"Pierrick Herve","photoUrl":"https://lh3.googleusercontent.com/-k_fs7F7thlQ/AAAAAAAAAAI/AAAAAAAAAdA/hM4l3zul944/s64/photo.jpg","userId":"05416953357448572451"}}},"cell_type":"code","source":["build_image_folder_200()"],"execution_count":57,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]\n"],"name":"stderr"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-2c48aabca312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbuild_image_folder_200\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-56-c846b386dbff>\u001b[0m in \u001b[0;36mbuild_image_folder_200\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{folder}/frame_{i:03}.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_200\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/image_200\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' mv image_200.zip \"/content/gdrive/My Drive/AED/\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0mbase_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/image_200'"]}]},{"metadata":{"id":"Lw2mdiR5b0AI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":374},"outputId":"3629f81f-2520-4a7c-c120-b401ad0c5c49","executionInfo":{"status":"error","timestamp":1541751877403,"user_tz":-60,"elapsed":512,"user":{"displayName":"Pierrick Herve","photoUrl":"https://lh3.googleusercontent.com/-k_fs7F7thlQ/AAAAAAAAAAI/AAAAAAAAAdA/hM4l3zul944/s64/photo.jpg","userId":"05416953357448572451"}}},"cell_type":"code","source":["import cv2\n","import os\n","#from imageio import imread\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.decomposition import PCA\n","REP = 'data/images_200'"],"execution_count":14,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-38ac31b487d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimageio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imageio'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"metadata":{"id":"z5dvaioYhze9","colab_type":"text"},"cell_type":"markdown","source":["####Videos to frame per cut"]},{"metadata":{"id":"bKNNaHkwhngU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":131},"outputId":"0c3727ce-200e-488c-a59c-366c41b85624","executionInfo":{"status":"error","timestamp":1541766648744,"user_tz":-60,"elapsed":531,"user":{"displayName":"Pierrick Herve","photoUrl":"https://lh3.googleusercontent.com/-k_fs7F7thlQ/AAAAAAAAAAI/AAAAAAAAAdA/hM4l3zul944/s64/photo.jpg","userId":"05416953357448572451"}}},"cell_type":"code","source":["# def cut(distance):\n","#     seuil = 60000  # A affiner\n","#     cuts = [0]\n","#     for i in range(1,len(distance)):\n","#         if distance[i] > seuil:\n","#             cuts.append(i)\n","#     return len(cuts), cuts\n","\n","#     for name in tqdm(glob.glob(\"data/image_200/*\")[start:end]):\n","#         images_200 = folder_to_list(name)\n","#         features = []\n","#         for frame in images_200:\n","#             folder_to_list_grey(folder)                for h in histo:\n","#                     features.append(int(h))\n","\n","\n","# def cuts(seq):\n","#     distance = []\n","#     cuts = [0]\n","#     for i in range(1, len(seq) - 1):\n","#         r, v, b = cv2.calcHist(seq[i], [color], None, [256], [0, 256]) for color in [0, 1, 2]\n","#         h1 = (r+v+b)/3\n","#         r, v, b = histogramme(seq[i+1])\n","#         h2 = (r+v+b)/3\n","#         distance.append(dist_Manhattan(h1, h2))\n","#         if dist_Manhattan(h1, h2) > 0.3:  # seuil à affiner\n","#             cuts.append(i)    \n","#     return cuts\n","\n","\n","\n","\n","# folder_to_list_grey(folder)\n","\n"],"execution_count":44,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-e80e5216c10c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for name in tqdm(glob.glob(\"data/image_200/*\")[start:end]):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"]}]},{"metadata":{"id":"F_yRCh-KmSq9","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"XNX_FAarkJl1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"a1a6eff3-a4ad-489f-c9f6-842b39b184b6","executionInfo":{"status":"ok","timestamp":1541768053946,"user_tz":-60,"elapsed":2689,"user":{"displayName":"Camille Roger","photoUrl":"https://lh4.googleusercontent.com/-DWxBAfpHjFo/AAAAAAAAAAI/AAAAAAAAACM/fUiCMCih2Wg/s64/photo.jpg","userId":"02582327179999629882"}}},"cell_type":"code","source":["def process_cuts(start=None, end=None):\n","    dic = {}\n","    for name in tqdm(sorted(glob.glob(\"data/image_sec/*\"))[start:end]):\n","        seq = folder_to_list_grey(name)\n","        dist = []\n","        for i in range(len(seq) -1):\n","            histo1 = cv2.calcHist(seq[i], [0], None, [256], [0, 256])\n","            histo1 = cv2.calcHist(seq[i+1], [0], None, [256], [0, 256])\n","\n","#     distance = []\n","#     cuts = [0]\n","#     for i in range(1, len(seq) - 1):\n","#         r, v, b = cv2.calcHist(seq[i], [color], None, [256], [0, 256]) for color in [0, 1, 2]\n","#         h1 = (r+v+b)/3\n","#         r, v, b = histogramme(seq[i+1])\n","#         h2 = (r+v+b)/3\n","#         distance.append(dist_Manhattan(h1, h2))\n","#         if dist_Manhattan(h1, h2) > 0.3:  # seuil à affiner\n","#             cuts.append(i)    \n","\n","    return pd.DataFrame.from_dict(dic, orient=\"index\")\n","\n","process_cuts(end=2)"],"execution_count":64,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n"," 50%|█████     | 1/2 [00:01<00:01,  1.62s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["61\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 2/2 [00:02<00:00,  1.31s/it]\u001b[A\n","\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["23\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"]},"metadata":{"tags":[]},"execution_count":64}]},{"metadata":{"id":"D5GyVASKqnr6","colab_type":"text"},"cell_type":"markdown","source":["216 : plan séquence"]},{"metadata":{"id":"SCtZKEIKR97I","colab_type":"text"},"cell_type":"markdown","source":["###Calculate the momentum (amount of movement)"]},{"metadata":{"id":"POgETy8NqPlf","colab_type":"text"},"cell_type":"markdown","source":["####Naïve version"]},{"metadata":{"id":"wUcsxBVdn7v4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":131},"outputId":"f56813d0-6fea-4d0f-f9da-fef64c5179bf","executionInfo":{"status":"error","timestamp":1541758427681,"user_tz":-60,"elapsed":532,"user":{"displayName":"Pierrick Herve","photoUrl":"https://lh3.googleusercontent.com/-k_fs7F7thlQ/AAAAAAAAAAI/AAAAAAAAAdA/hM4l3zul944/s64/photo.jpg","userId":"05416953357448572451"}}},"cell_type":"code","source":["import numpy as np\n","import cv2\n","import glob\n","\n","# pas utilisé\n","\n","# fichiers annotés violents\n","violence = {'SEQ_001_VIDEO','SEQ_011_VIDEO','SEQ_013_VIDEO','SEQ_016_VIDEO','SEQ_018_VIDEO','SEQ_025_VIDEO','SEQ_026_VIDEO','SEQ_034_VIDEO','SEQ_036_VIDEO','SEQ_037_VIDEO','SEQ_045_VIDEO','SEQ_047_VIDEO','SEQ_061_VIDEO','SEQ_062_VIDEO','SEQ_097_VIDEO','SEQ_103_VIDEO','SEQ_104_VIDEO','SEQ_106_VIDEO','SEQ_110_VIDEO','SEQ_112_VIDEO','SEQ_114_VIDEO','SEQ_115_VIDEO','SEQ_116_VIDEO','SEQ_130_VIDEO','SEQ_131_VIDEO','SEQ_141_VIDEO','SEQ_162_VIDEO','SEQ_169_VIDEO','SEQ_181_VIDEO','SEQ_193_VIDEO','SEQ_203_VIDEO','SEQ_219_VIDEO','SEQ_221_VIDEO','SEQ_223_VIDEO','SEQ_224_VIDEO','SEQ_225_VIDEO','SEQ_227_VIDEO','SEQ_233_VIDEO','SEQ_234_VIDEO','SEQ_235_VIDEO','SEQ_238_VIDEO','SEQ_241_VIDEO','SEQ_264_VIDEO','SEQ_265_VIDEO','SEQ_270_VIDEO','SEQ_271_VIDEO','SEQ_275_VIDEO','SEQ_277_VIDEO','SEQ_278_VIDEO','SEQ_279_VIDEO','SEQ_281_VIDEO','SEQ_289_VIDEO','SEQ_294_VIDEO','SEQ_295_VIDEO','SEQ_298_VIDEO','SEQ_301_VIDEO','SEQ_302_VIDEO','SEQ_307_VIDEO'}\n","\n","for videopath in sorted(glob.glob(\"data/video/*.mp4\")):\n","\n","    name = os.path.splitext(os.path.basename(videopath))[0]\n","    \n","    if (name is in violence):\n","        # 002 => 55\n","        # 003 => 5\n","        # 009 => 16\n","        # 012 => 12\n","        # 047 => 23\n","        # 004 => 14\n","        # 006 => 6\n","        # 013 => 17\n","        # 016 => 1,6 à l'audio de repérer celle ci\n","\n","        cap = cv2.VideoCapture(videopath)\n","\n","        # params for ShiTomasi corner detection\n","        feature_params = dict( maxCorners = 100,\n","                               qualityLevel = 0.3,\n","                               minDistance = 7,\n","                               blockSize = 7 )\n","\n","        # Parameters for lucas kanade optical flow\n","        lk_params = dict( winSize  = (15,15),\n","                          maxLevel = 2,\n","                          criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","\n","        # Create some random colors\n","        color = np.random.randint(0,255,(100,3))\n","\n","        # Take first frame and find corners in it\n","        ret, old_frame = cap.read()\n","        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n","        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n","\n","        # Create a mask image for drawing purposes\n","        mask = np.zeros_like(old_frame)\n","\n","        distance = 0\n","\n","        while(ret):\n","            ret, frame = cap.read()\n","            if (frame is not None):\n","                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","                # calculate optical flow\n","                p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n","\n","                # Select good points\n","\n","                if (p1 is None):\n","                    good_new = p0[st==1]\n","                else:\n","                    good_new = p1[st==1]\n","                good_old = p0[st==1]\n","\n","                # draw the tracks\n","                for i,(new,old) in enumerate(zip(good_new,good_old)):\n","                    a,b = new.ravel()\n","                    c,d = old.ravel()\n","                    mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n","                    distance += np.sqrt((a - c)**2 + (b - d)**2)\n","                frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n","                img = cv2.add(frame,mask)\n","                #print(distance)\n","\n","            #     cv2.imshow('frame',img)\n","            #     k = cv2.waitKey(30) & 0xff\n","            #     if k == 27:\n","            #         break\n","\n","                # Now update the previous frame and previous points\n","                old_gray = frame_gray.copy()\n","                p0 = good_new.reshape(-1,1,2)\n","\n","\n","        number_of_frames = int(cap.get(7))\n","        mean_movement = distance/number_of_frames\n","#         if (mean_movement > 45):\n","        print(f\"Name: {name}   Movement: {mean_movement}\")\n","\n","\n","    cv2.destroyAllWindows()\n","    cap.release()"],"execution_count":21,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-ff70809bf318>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    if (name is in violence):\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"metadata":{"id":"-N3XSSHWqkgW","colab_type":"text"},"cell_type":"markdown","source":["####Smart version"]},{"metadata":{"id":"dt_8cSybopJT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":49},"outputId":"839fb055-babd-401c-8dc9-fcfcc69edb4f","executionInfo":{"status":"ok","timestamp":1541767143278,"user_tz":-60,"elapsed":821,"user":{"displayName":"Pierrick Herve","photoUrl":"https://lh3.googleusercontent.com/-k_fs7F7thlQ/AAAAAAAAAAI/AAAAAAAAAdA/hM4l3zul944/s64/photo.jpg","userId":"05416953357448572451"}}},"cell_type":"code","source":["import cv2\n","import numpy as np\n","from tqdm import tqdm\n","\n","\n","# def optical_flow_smart(videopath):\n","#     cam = cv2.VideoCapture(videopath)\n","#     ret, img = cam.read()\n","#     prevgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","#     res = []\n","#     while ret:\n","#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","#         flow = cv2.calcOpticalFlowFarneback(prevgray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","#         prevgray = gray\n","#         res.append(np.sum(flow))\n","#         ret, img = cam.read()\n","#     return np.sum(res)\n","\n","def quant(img, flow, step=16):\n","    h, w = img.shape[:2]\n","    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2,-1).astype(int)\n","    fx, fy = flow[y,x].T\n","    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n","    lines = np.int32(lines + 0.5)\n","    tot = []\n","    for (x1, y1), (x2, y2) in lines:\n","        tot.append(np.sqrt((x2 - x1)**2 + (y2 - y1)**2))\n","    return np.sum(np.abs(np.abs(tot) - np.mean(np.abs(tot))))\n","\n","\n","def optical_flow_smart(videopath):\n","    frames = folder_to_list(videopath)\n","    res = []\n","    paths = sorted(glob.glob(f\"{videopath}/*.jpg\"))\n","    prevgray = cv2.imread(paths[0], 0)\n","    for path in paths[1:]:\n","        distance = 0\n","        gray = cv2.imread(path, 0)\n","        flow = cv2.calcOpticalFlowFarneback(prevgray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","        q = quant(gray, flow)\n","        res.append(q)\n","    return res\n","\n","def process_momentum(start=None, end=None):\n","    dic = {}\n","    for name in tqdm(sorted(glob.glob(\"data/image_200/*\"))[start:end]):\n","#         images_200 = folder_to_list(name)\n","        features = []\n","        for path in glob.glob(name):\n","            res = optical_flow_smart(path)\n","            plt.plot(res)\n","            plt.title(path)\n","            plt.show()\n","            features = []\n","            for i in range(len(res)):\n","                features.append(res[i])\n","        dic[name[15:]] = features\n","    return pd.DataFrame.from_dict(dic, orient=\"index\")\n","\n","\n","\n","# prompt histograms\n","# for path in tqdm((sorted(glob.glob(\"data/image_sec/*\")))):\n","#     plot data\n","#     plt.plot(optical_flow_smart(path))\n","#     plt.title(path)\n","#     plt.show()\n","    \n","df_momentum = process_momentum()\n","df_momentum.to_csv(\"df_momentum.csv\", sep=\"§\")\n","df_momentum\n","\n","    "],"execution_count":52,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"]},"metadata":{"tags":[]},"execution_count":52}]},{"metadata":{"id":"2rTwZ5MTnnQU","colab_type":"text"},"cell_type":"markdown","source":["##Classification"]},{"metadata":{"id":"_CLDH-ntpADz","colab_type":"text"},"cell_type":"markdown","source":["###Intérieur/Extérieur avec les cuts"]},{"metadata":{"id":"f1pc9K8xpnZ3","colab_type":"text"},"cell_type":"markdown","source":["####KNN"]},{"metadata":{"id":"_gEkk0AfqreG","colab_type":"code","colab":{}},"cell_type":"code","source":["def KNN_plus_gridsearch(X, y, n_neighbors_knn, n_neighbors_grid):\n","\n","    #KNN\n","    # split and shuffle X and y\n","    TEST_SIZE = np.int(np.floor(len(y)*0.7))\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)\n","\n","    # train\n","    n_neighbors = n_neighbors_knn\n","    clf = KNeighborsClassifier(n_neighbors)\n","    #TODO: fit le modèle 1 seule fois\n","    clf.fit(X_train, y_train)\n","\n","    # predict\n","    #TODO: prédire toujours sur les mêmes vidéos pour pouvoir comparer l'accuracy des prédictions avec différents paramètrages\n","    y_pred = clf.predict(X_test)\n","    \n","    # transform into dataframe\n","    y_pred = pd.DataFrame(y_pred)\n","    y_pred.index = y_test.index\n","    df = pd.concat([y_pred, y_test], axis=1)\n","    df.columns = ['pred', 'test']\n","\n","    # confusion matrix\n","    confusion = confusion_matrix(y_test, y_pred)\n","    confusion = pd.DataFrame(data=confusion, index=[\"A\", \"B\"], columns=[\"X\", \"Y\"])\n","\n","    #accuracy\n","    acc = 0\n","    for i in df.index:\n","        if (df['test'][i]==df['pred'][i]):\n","            acc +=1\n","    acc = acc/len(df)\n","    \n","    \n","    # GRID SEARCH\n","    # parameters\n","    myList = list(range(1,n_neighbors_grid))\n","    n = filter(lambda x: x % 2 != 0, myList)\n","    parameters = {'n_neighbors':n}\n","\n","    # learn with grid search\n","    model = grid_search.GridSearchCV(clf, parameters)\n","    #TODO: fit le modèle 1 seule fois\n","    model.fit(X_train, y_train)\n","    \n","    # le best k trouvé est à priori dans les paramètres\n","    params = model.cv_results_.keys()\n","\n","    \n","    return df, confusion, acc, params\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h4W-arpouZjQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"ef2545a7-6ec5-4b27-fbc5-3a2390e14ae6","executionInfo":{"status":"error","timestamp":1541766739582,"user_tz":-60,"elapsed":780,"user":{"displayName":"Pierrick Herve","photoUrl":"https://lh3.googleusercontent.com/-k_fs7F7thlQ/AAAAAAAAAAI/AAAAAAAAAdA/hM4l3zul944/s64/photo.jpg","userId":"05416953357448572451"}}},"cell_type":"code","source":["# get in/out classification\n","y_inout = pd.read_csv(PATH+\"Annotations.csv\")[[\"Exterieur\"]]\n","\n","df, confusion, acc, params= KNN_plus_gridsearch(X_cuts, y_inout, 2, 50)\n","print (df)\n","print (confusion)\n","print(f\"accuracy: {acc}\")"],"execution_count":48,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-494e641f1dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_inout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"Annotations.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Exterieur\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mKNN_plus_gridsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cuts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_inout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_cuts' is not defined"]}]},{"metadata":{"id":"d24F10zgQcJ9","colab_type":"text"},"cell_type":"markdown","source":["####Grid search (to find the best number of nearest neighbors)"]},{"metadata":{"id":"DUWXJV0QNKDQ","colab_type":"text"},"cell_type":"markdown","source":["####Prédictions\n","\n","Paramètres modifiable:\n","- seuil de détection des cuts (seuil)\n","- nombre de plus proches voisins (voisins)\n","\n","Résultat :\n","- accuracy (acc)\n","\n"]},{"metadata":{"id":"B2e7lfi0dQYO","colab_type":"text"},"cell_type":"markdown","source":["### clasif intérieur/extérieur avec la luminosité ?\n","https://stackoverflow.com/questions/14243472/estimate-brightness-of-an-image-opencv\n","    \n","    "]},{"metadata":{"id":"u2MznLhvp7Gu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":49},"outputId":"75e3ab63-2f78-4fdc-dd57-df0937e44987","executionInfo":{"status":"ok","timestamp":1541767144052,"user_tz":-60,"elapsed":618,"user":{"displayName":"Pierrick Herve","photoUrl":"https://lh3.googleusercontent.com/-k_fs7F7thlQ/AAAAAAAAAAI/AAAAAAAAAdA/hM4l3zul944/s64/photo.jpg","userId":"05416953357448572451"}}},"cell_type":"code","source":["def process_histo(start=None, end=None):\n","    dic = {}\n","    for name in tqdm(glob.glob(\"data/image_200/*\")[start:end]):\n","        images_200 = folder_to_list(name)\n","        features = []\n","        for frame in images_200:\n","            for histo in [cv2.calcHist(frame, [color], None, [256], [0, 256]) for color in [0, 1, 2]]:\n","                for h in histo:\n","                    features.append(int(h))\n","        dic[name[15:]] = features\n","    return pd.DataFrame.from_dict(dic, orient=\"index\")\n","\n","df_histo = process_histo()\n","df_histo"],"execution_count":53,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"]},"metadata":{"tags":[]},"execution_count":53}]},{"metadata":{"id":"RfB0v40Lewyx","colab_type":"code","colab":{}},"cell_type":"code","source":["df_histo.to_csv(\"df_histo.csv\", sep=\"§\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yeWgSuYJsxZr","colab_type":"text"},"cell_type":"markdown","source":["###Violent/Non-violent avec le momentum"]},{"metadata":{"id":"ChMMYbyAs3-s","colab_type":"code","colab":{}},"cell_type":"code","source":["# get violent/non-violent classification\n","y_violent = pd.read_csv(PATH+\"Annotations.csv\")[[\"Violent\"]]\n","\n","df, confusion, acc, params = KNN_plus_gridsearch(X_momentum, y_violent, 2, 50)\n","print (df)\n","print (confusion)\n","print(f\"accuracy: {acc}\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sGIUM43aAGPo","colab_type":"text"},"cell_type":"markdown","source":["##Restitution"]},{"metadata":{"id":"dkcPqW2mAKNr","colab_type":"code","colab":{}},"cell_type":"code","source":["import plotly.graph_objs as go\n","from plotly.offline import download_plotlyjs, plot, iplot\n","import numpy as np\n","\n","# merci Adil\n","def plot_cluster(coords, names, labels, name_plot):\n","    ''' \n","    Create a scatter plot\n","    \n","    Arguments:\n","        coords {numpy array} -- A numpy array with N lines and 2 columns \n","                                (N=number of individuals) each column \n","                                correspond to a dimension\n","        names {list} -- list corresponding to the names of the individuals\n","        labels {type} -- Label of the cluster (an integer like 0 for the first cluster, 1 for the second...)\n","        name_plot {str} -- name of the html file of the plot\n","    '''\n","\n","    # Create a trace\n","    trace = go.Scatter(\n","        x = coords[:, 0],\n","        y = coords[:, 1],\n","        mode = 'markers',\n","        text = names,\n","        marker = dict(\n","            size = 10,\n","            color = labels,\n","            line = dict(\n","                width = 2,\n","                color = 'rgb(0, 0, 0)'\n","            )\n","        )\n","    )\n","\n","    data = [trace]\n","\n","    layout = dict(title = 'Styled Scatter',\n","                    yaxis = dict(zeroline = False),\n","                    xaxis = dict(zeroline = False)\n","                    )\n","\n","    fig = dict(data=data, layout=layout)\n","    plot(fig, filename=name_plot)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JaXiUztmAOFu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":183},"outputId":"a648fd1c-4ae2-42d5-b338-1da1fb9a99d6","executionInfo":{"status":"error","timestamp":1541766528585,"user_tz":-60,"elapsed":543,"user":{"displayName":"Pierrick Herve","photoUrl":"https://lh3.googleusercontent.com/-k_fs7F7thlQ/AAAAAAAAAAI/AAAAAAAAAdA/hM4l3zul944/s64/photo.jpg","userId":"05416953357448572451"}}},"cell_type":"code","source":["df_histo.to_csv(\"df_histo.csv\", sep = \"§\")\n","df_momentum.to_csv(\"df_momentum.csv\",  sep = \"§\")\n","\n"],"execution_count":34,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-d2fa40929fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_momentum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_momentum\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"§\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_momentum' is not defined"]}]},{"metadata":{"id":"cqgIdR-Tc4zI","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}