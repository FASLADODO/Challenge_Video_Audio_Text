{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from math import log\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.corpus import wordnet\n",
    "#import nltk\n",
    "#nltk.download()\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Plotly imports\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pydeepl\n",
    "import codecs\n",
    "from scipy.misc import imread\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mickael/anaconda3/envs/TAV/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning:\n",
      "\n",
      "Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/mickael/Documents/Challenge_Video_Audio_Text/features/text/sequence_text.csv', sep='§')\n",
    "\n",
    "data = data.groupby(['Sequence'])['Text'].sum() # Découper par séquence ou réplique\n",
    "data = data.reset_index()\n",
    "data['Text'] = [x.lower() for x in data['Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('french'))\n",
    "stop.update(['.', ',', '\"', \"'\", '?', '!', ':',\n",
    "                   ';', '(', ')', '[', ']', '{', '}','-','...', '..', '«', '»' ,\"'\", \"’\", \"``\", \"''\",\n",
    "            'le', 'la', 'les', 'un', 'une', 'des', 'or', 'ni', 'car', 'assez', 'aussitôt', 'assez', \n",
    "             'car', 'des', 'la', 'le', 'les', 'ni', 'or', 'un', 'une',\n",
    "            'a', \"C'est\", 'Vous', 'ça', \"c'est\", 'Et', 'Plus', 'Mais', 'Tout', \"qu'il\",\n",
    "            'Le', 'quoi', \"qu'il\", 'si', 'là', 'Ah', 'sais', 'rien', \"j'ai\", 'Ça', 'Ce', 'Si', 'deux', 'peu',\n",
    "            'Cette', 'moi', 'oh', 'Les', 'En', 'Oh', 'A', 'Ca', 'Un', 'Va','va', 'C', \"m'a\", 'vais', 'Vais',\n",
    "            'un', 'Un', 'La', 'aussi', 'très', 'tout', 'plus', 'alors', 'faut', 'trois', 'dire', 'faire',\n",
    "            'être', 'sans', \"C'était\", 'crois', 'ils', 'Une', 'alors', 'peux', 'faut',\"qu'on\", 'Alors', 'cette', \n",
    "            'dit', \"d'un\", 'dis', 'Il', 'On', 'on', 'tu', 'Tu', \"J'ai\", \"j'ai\", 'J', 'Quand', 'quand', 'elle',\n",
    "            'tous', 'allez', 'moi', 'voilà', 'cent', 'ou', 'pour', 'hein', 'ils', \"j'en\", \"qu'est-ce\", 'mon',\n",
    "            'ans','fois', 'avec', 'fais','avec', \"n'est\", 'nous', 'vous', 'fait', 'moi', 'ah', 'puis', 'tant',\n",
    "            'autre', \"t'es\", 'juste', 'peut', 'tu', 'où', \"t'a\", \"t'as\", \"c'est\", 'autre', 'bah', 'après',\n",
    "            'comme', \"qu'elle\", \"c'était\", 'ben', 'veut', 'je', \"s'est\", 'ca', 'quelle', \"qu'elle\", 'chez',\n",
    "            \"d'une\", \"d'un\", 'ouais', 'ouai', 'tu', 'trop', 'veut', 'prend', \"d'être\", 'parce', 'vous', 'nous',\n",
    "            'toute', 'quatre', 'se', 'ce', 'tout', 'toute', 'parce', 'huit', 'quel', 'déjà', 'dix', 'huit',\n",
    "            'cela', 'Le', 'nom', 'six', \"l'a\", \"qu'il\", 'coté', \"l'ai\", \"qu'un\", \"n'a\", 'cet', 'cette', 'pour'])\n",
    "\n",
    "data['Text'] = data['Text'].apply(\n",
    "    lambda x: ' '.join([i for i in word_tokenize(x) if i not in stop])) \n",
    "# data.iloc[5] data = [data['Text']]\n",
    "#print(data.groupby('Text').apply(' '.join).reset_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fenetre = [] # liste des 308 séquences sous forme de fenetre\n",
    "for i in data['Text']:\n",
    "    fenetre.append([i])\n",
    "fenetre = [sentence.split() for f in fenetre for sentence in f] # une fenetre : une séquence\n",
    "#[f.split() for f in fenetre[0]]\n",
    "len(fenetre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pydeepl.translate(data['Text'], to_language, from_lang=from_language)\n",
    "liste = []\n",
    "for i in data['Text']:\n",
    "    liste.append(i)\n",
    "liste = \" \".join(liste).split()\n",
    "liste = liste[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bda19061862a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfrom_language\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FR'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mto_language\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EN'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mliste_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mliste\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mpydeepl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'EN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "from_language = 'FR'\n",
    "to_language = 'EN'\n",
    "liste_en = liste.apply(lambda x :pydeepl.translate(x,'EN', 'FR'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:47<00:00,  2.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from_language = 'FR'\n",
    "to_language = 'EN'\n",
    "liste_en = []\n",
    "for i in tqdm(liste):\n",
    "    trad = pydeepl.translate(i, to_language, from_language)\n",
    "    liste_en.append(trad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['helpless', 'bush', 'sir', 'meyer', 'theories']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_en[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = np.array([ppmi_tot[liste.index(i)] for i in ['']])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "Xp = pca.fit_transform(X)\n",
    "red = [0]\n",
    "bleu = [1]\n",
    "\n",
    "plt.plot([x[0] for x in Xp[red]],[x[1] for x in Xp[red]], 'ro')\n",
    "plt.plot([x[0] for x in Xp[bleu]],[x[1] for x in Xp[bleu]], 'bx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarité(liste)  :  \n",
    "    liste_synonyme = []\n",
    "    for mot1 in liste:\n",
    "         if wordnet.synsets(mot1)!=[]:\n",
    "            liste_synonyme.append(mot1)     \n",
    "    similarité = [[0 for i in range(len(liste_synonyme))] for i in range(len(liste_synonyme))]\n",
    "    for mot1 in liste_synonyme:\n",
    "        for mot2 in liste_synonyme:\n",
    "                synonyme1 = wordnet.synsets(mot1)[0] # On prendra toujours le premier sens\n",
    "                synonyme2 = wordnet.synsets(mot2)[0]\n",
    "                similarité[liste_synonyme.index(mot1)][liste_synonyme.index(mot2)] = synonyme1.path_similarity(synonyme2)\n",
    "    return similarité\n",
    "\n",
    "sim = similarité(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = ['Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday', 'Saturday','Sunday',\\\n",
    "              'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August',\\\n",
    "              'September', 'October', 'November', 'December']\n",
    "\n",
    "DATE_similarité = similarité(DATE)\n",
    "\n",
    "X = np.array(DATE_similarité)\n",
    "pca = PCA(n_components=2)\n",
    "Xp = pca.fit_transform(X)\n",
    "\n",
    "red = [0,1,2,3,4,5] \n",
    "green = [6]\n",
    "bleu = [7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "\n",
    "plt.plot([x[0] for x in Xp[red]],[x[1] for x in Xp[red]], 'ro')\n",
    "plt.plot([x[0] for x in Xp[green]],[x[1] for x in Xp[green]], 'gx')\n",
    "plt.plot([x[0] for x in Xp[bleu]],[x[1] for x in Xp[bleu]], 'bx')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
